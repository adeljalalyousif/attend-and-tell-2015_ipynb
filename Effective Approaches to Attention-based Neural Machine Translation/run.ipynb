{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "from helpers import load_config\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string   \n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Data\n",
    "\n",
    "Install the data using keras's `get_file` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = config[\"dataset\"]\n",
    "path_to_zip = tf.keras.utils.get_file(os.path.join(os.getcwd(), \"datasets\", \"fra-eng.zip\"), origin=dataset_params[\"url\"], extract=True)\n",
    "path_to_file = os.path.join(os.path.dirname(path_to_zip), \"fra.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "For preprocessing, we will do the following:\n",
    "\n",
    "- Clean the sentences from special characters.\n",
    "- Add starting and ending tokens.\n",
    "- Create a vocabulary.\n",
    "- Pad each sentence to the maximum.\n",
    "- Batch and prefetch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    # make a space between each punctionation\n",
    "    sentence = sentence.translate(str.maketrans({key: \" {0} \".format(key) for key in string.punctuation}))\n",
    "    \n",
    "    sentence = sentence.strip()  # remove spaces\n",
    "    return sentence\n",
    "\n",
    "def preprocess_a_sentence(sentence):\n",
    "    # clean it\n",
    "    sentence = clean_sentence(sentence)\n",
    "    # add the start and end of sequences\n",
    "    return '<sos> {} <eos>'.format(sentence)\n",
    "\n",
    "def load_dataset(path, num_examples=None):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "    # list containing a set of (input, output)\n",
    "    sentence_pairs = [[preprocess_a_sentence(sen) for sen in line.split('\\t')]  for line in lines[:num_examples]]\n",
    "    return zip(*sentence_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> Run ! <eos> <sos> Courez  ! <eos>\n"
     ]
    }
   ],
   "source": [
    "en, fr = load_dataset(path_to_file)\n",
    "print(en[3], fr[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(lang):\n",
    "    \n",
    "    # we are keeping the punctionation\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='’,?!\"#$%&()*+-/:;=.@[\\\\]^_`{|}~\\t\\n')\n",
    "    tokenizer.fit_on_texts(lang)\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences(lang)\n",
    "    # pad the tensors\n",
    "    sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding=\"post\")\n",
    "    return sequences, tokenizer\n",
    "\n",
    "def create_dataset(X, y, batch_size=None, buffer=False, prefetch=tf.data.experimental.AUTOTUNE):\n",
    "    a_set = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if buffer:\n",
    "        a_set = a_set.shuffle(X.shape[0])\n",
    "    if batch_size is not None:\n",
    "        a_set = a_set.batch(batch_size, drop_remainder=True)\n",
    "    return a_set.prefetch(prefetch)\n",
    "\n",
    "def dataset(path, batch_size, num_examples=None, prefetch=tf.data.experimental.AUTOTUNE, test_size=0.2):\n",
    "    target_lang, input_lang = load_dataset(path, num_examples=num_examples)\n",
    "    \n",
    "    input_sequences, input_tokenizer = get_tokenizer(input_lang)\n",
    "    target_sequences, target_tokenizer = get_tokenizer(target_lang)\n",
    "    \n",
    "    input_train_seq, input_test_seq, target_train_seq, target_test_seq = train_test_split(input_sequences, \n",
    "                                                                                          target_sequences, \n",
    "                                                                                          test_size=test_size)\n",
    "    \n",
    "    train_set = create_dataset(input_train_seq, target_train_seq, \n",
    "                               batch_size=batch_size, buffer=True,\n",
    "                               prefetch=prefetch)\n",
    "    test_set = create_dataset(input_test_seq, target_test_seq, prefetch=prefetch)\n",
    "    return train_set, test_set, input_train_seq.shape[0], input_tokenizer, target_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = dataset_params[\"batch_size\"]\n",
    "num_examples = dataset_params[\"num_examples\"]\n",
    "train_set, test_set, train_size, input_tokenizer, target_tokenizer = dataset(path_to_file, batch_size, num_examples=num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos> je suis soûl <eos>']\n",
      "[\"<sos> i ' m drunk <eos>\"]\n"
     ]
    }
   ],
   "source": [
    "for x, y, in train_set.take(1):\n",
    "    i = 8\n",
    "    print(input_tokenizer.sequences_to_texts([x[i].numpy()]))\n",
    "    print(target_tokenizer.sequences_to_texts([y[i].numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Encoder, Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = config[\"model\"]\n",
    "\n",
    "epochs = model_params[\"epochs\"]\n",
    "embedding_dim = model_params[\"embedding_dim\"]\n",
    "units = model_params[\"units\"]\n",
    "bidirectional = model_params[\"bidirectional\"]\n",
    "\n",
    "steps_per_epoch = train_size // batch_size\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_vocab_size, embedding_dim, units, bidirectional=bidirectional)\n",
    "decoder = Decoder(target_vocab_size, embedding_dim, units, bidirectional=bidirectional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # set mask True to everywhere but zero (zero is the padding)\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "The training's steps are:\n",
    "\n",
    "1. Pass the input through the encoder and get the encoder's outputs and the states.\n",
    "\n",
    "2. The encoder output and hidden states and the decoder state's is passed to the decoder.\n",
    "\n",
    "3. We feed the encoder's input, state and token to decoder:\n",
    "    - The decoder will spit the output and hidden state\n",
    "    - The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "    - Use Teacher Forcing to decide the next input to the decoder.\n",
    "    - Repeat for each time step in the decoder's input.\n",
    "4. The final step is to calculate the gradients and apply it to the optimizer and backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(X, y):\n",
    "    loss = 0\n",
    "    batch_size = X.shape[0]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(X)\n",
    "        \n",
    "        dec_hidden = enc_hidden\n",
    "        # target input at the begining should only be <start>\n",
    "        dec_input = tf.expand_dims([target_tokenizer.word_index['<sos>']] * batch_size, 1)\n",
    "        \n",
    "        for t in range(1, y.shape[1]): # starting from 1 as we created the <start> above.\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            loss += loss_function(y[:, t], predictions)  # compute the loss based on the predictions\n",
    "            \n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(y[:, t], 1)  # here we give the actual target and not the predictions as input.\n",
    "        \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)\n",
    "\n",
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    for (step, (X, y)) in enumerate(train_set.take(steps_per_epoch)):\n",
    "        loss = train_step(X, y)  # for each epoch, step, we are reseting the states (it is not stateful)\n",
    "        train_loss(loss)\n",
    "        \n",
    "        print_status_bar(step * batch_size, train_size, train_loss, None)\n",
    "        \n",
    "    print_status_bar(train_size, train_size, train_loss, None)\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To evaluate and chek the performance of the model, we will do the following:\n",
    "\n",
    "- Write evaluation function for the test data (similar to training loop but without teacher forcing.\n",
    "- Stop predicting when the model predicts the end token\n",
    "- Store the attention weights fore very time step for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "   \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate(inputs, max_target_pad):\n",
    "    \n",
    "    attention_plot = np.zeros((max_target_pad, inputs.shape[0]))\n",
    "    \n",
    "    # convert from words to sequence\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # running the encoder\n",
    "    enc_output, dec_hidden = encoder(tf.expand_dims(inputs, 0))\n",
    "    \n",
    "    dec_input = tf.expand_dims([target_tokenizer.word_index['<sos>']], 0)\n",
    "    \n",
    "    for t in range(max_target_pad):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_output)\n",
    "        \n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        predicted_word = target_tokenizer.index_word[predicted_id]\n",
    "        if predicted_word  == '<eos>':\n",
    "            return \" \".join(result), attention_plot\n",
    "        \n",
    "        result.append(predicted_word)\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "    return \" \".join(result), attention_plot\n",
    "\n",
    "\n",
    "def translate(X, y):\n",
    "    sentence = input_tokenizer.sequences_to_texts([X.numpy()])[0]\n",
    "    translation = target_tokenizer.sequences_to_texts([y.numpy()])[0]\n",
    "    result, attention_plot = evaluate(X, y.shape[0])\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Actual translation: %s' % (translation))\n",
    "    print('Predicted translation: %s '% (result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <sos> c est triste <eos>\n",
      "Actual translation: <sos> it ' s sad <eos>\n",
      "Predicted translation: i ' m fair \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in test_set.take(1):\n",
    "    translate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Further Readings\n",
    "\n",
    "- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "- [Neural Machine Translation with Attention](https://www.tensorflow.org/tutorials/text/nmt_with_attention)\n",
    "- [Hands-on Machine Learning With Scikit-Learn, Keras & Tensorflow](https://github.com/ageron/handson-ml2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
